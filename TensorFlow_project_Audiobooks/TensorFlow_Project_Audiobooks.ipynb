{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **TensorFlow Project: Audiobooks**"
      ],
      "metadata": {
        "id": "ZqWl9exPDyKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract the data from the csv**"
      ],
      "metadata": {
        "id": "OneXc5bDElxE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qKU649pUDwg-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "raw_csv_data = np.loadtxt('sample_data/Audiobooks_data.csv', delimiter = ',')\n",
        "\n",
        "unscaled_inputs_all = raw_csv_data[:,1:-1]\n",
        "targets_all = raw_csv_data[:,-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**unscaled_inputs_all** [:,1:-1] 表示取所有行，去掉第一列（通常是 ID），去掉最后一列（标签 target），只留下中间的特征。所以 unscaled_inputs_all 就是 模型的输入数据。\n",
        "\n",
        "**targets_all** 提取最后一列作为 标签 (target)，也就是客户是否会再次购买有声书：1 = 会购买 0 = 不会购买"
      ],
      "metadata": {
        "id": "_2igM85Yy-LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unscaled_inputs_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLwlkmy2E5t1",
        "outputId": "56f59236-8e06-42ab-fc6b-a02ec679f5e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1620.  , 1620.  ,   19.73, ..., 1603.8 ,    5.  ,   92.  ],\n",
              "       [2160.  , 2160.  ,    5.33, ...,    0.  ,    0.  ,    0.  ],\n",
              "       [2160.  , 2160.  ,    5.33, ...,    0.  ,    0.  ,  388.  ],\n",
              "       ...,\n",
              "       [2160.  , 2160.  ,    6.14, ...,    0.  ,    0.  ,    0.  ],\n",
              "       [1620.  , 1620.  ,    5.33, ...,  615.6 ,    0.  ,   90.  ],\n",
              "       [1674.  , 3348.  ,    5.33, ...,    0.  ,    0.  ,    0.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets_all.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePytSj6lIfcN",
        "outputId": "1154b1fb-50c7-43ad-ecee-6e2bd5f109e8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14084"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Balance the dataset**"
      ],
      "metadata": {
        "id": "NmAGRiiiJkoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_one_targets = int(np.sum(targets_all)) # 计算所有 target 里 1 的数量，有多少个1（有多少人会买）\n",
        "zero_targets_counter = 0\n",
        "indices_to_remove = []\n",
        "\n",
        "for i in range(targets_all.shape[0]):\n",
        "  if targets_all[i] == 0:\n",
        "    zero_targets_counter += 1\n",
        "    if zero_targets_counter > num_one_targets:\n",
        "      indices_to_remove.append(i)\n",
        "\n",
        "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis = 0)\n",
        "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis = 0)"
      ],
      "metadata": {
        "id": "sLiR4UdMJk0c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**for loop(遍历所有样本)**\n",
        "\n",
        "如果当前行的 target = 0，就把 zero_targets_counter 加一。\n",
        "\n",
        "如果 0 的数量超过了 1 的数量，就把该行的索引记录下来。\n",
        "\n",
        "这样做的目的：\n",
        "⚡ 让 0 的数量不要比 1 多，即保证 0 和 1 的样本数量一致。(平衡购买和不购买的人)\n",
        "\n",
        "**np.delete** 用delete()把数据里多余出来的0删除掉，这样让数据里1的数量和0的数量一样，得到一个 正负样本平衡的训练集。"
      ],
      "metadata": {
        "id": "1D6YcXid0VKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在你这个 **Audiobooks 数据集里**，标签是：\n",
        "\n",
        "0 = 用户不会再买\n",
        "\n",
        "1 = 用户会再买\n",
        "\n",
        "原始分布是 **不平衡的（约 5:1），** 大部分人都不会再买。\n",
        "\n",
        "**为什么要平衡？**\n",
        "\n",
        "如果不做平衡，模型会学出一个很“偷懒”的策略：\n",
        "\n",
        "👉 只要预测所有人都 不会买 (0)，准确率就有 84%（因为 11,847/14,084 ≈ 0.84）。\n",
        "\n",
        "看似准确率很高，但实际上模型 没**有学到真正有价值的规律。**\n",
        "\n",
        "你最想预测的是：**哪些人会再买 (1)**，因为这是公司的盈利点。\n",
        "\n",
        "**如果 1 的样本太少**，模型在训练中会“忽略”它们，导致对正样本（会买的人）预测很差。"
      ],
      "metadata": {
        "id": "Wh-M37KESS9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Standardize the inputs**"
      ],
      "metadata": {
        "id": "W1RRa6ioQO7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)\n",
        "# 缩放数据 ex:（-1 0 1）"
      ],
      "metadata": {
        "id": "Cz15MS9fQVpc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shuffle the data**"
      ],
      "metadata": {
        "id": "wJNtToe8Qd0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
        "np.random.shuffle(shuffled_indices)\n",
        "\n",
        "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
        "shuffled_targets = targets_equal_priors[shuffled_indices]"
      ],
      "metadata": {
        "id": "HsHCNfnAQeAK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**np.arange()** 会创建一个从 0 到 N-1 的数组，其中 N 是样本的总数。例如，如果有 4474 个样本：[0, 1, 2, 3, 4, ..., 4473]\n",
        "\n",
        "**np.random.shuffle()** 随机打乱这些索引\n",
        "\n",
        "**shuffled_inputs shuffled_targets** 把打乱的索引放进这两个数组里面，这样就把inputs和targets一起 随机打乱 了，防止模型学习到数据集的顺序模式。"
      ],
      "metadata": {
        "id": "S_7bBKzpcOFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the dataset into train, validation, and test**"
      ],
      "metadata": {
        "id": "aB3dCrsHQg60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_count = shuffled_inputs.shape[0] # shape[0]是算出number of the element\n",
        "\n",
        "train_sample_count = int(0.8*sample_count)\n",
        "validation_sample_count = int(0.1*sample_count)\n",
        "test_sample_count = sample_count - train_sample_count - validation_sample_count\n",
        "\n",
        "train_inputs = shuffled_inputs[:train_sample_count]\n",
        "train_targets = shuffled_targets[:train_sample_count]\n",
        "\n",
        "validation_inputs = shuffled_inputs[train_sample_count:train_sample_count + validation_sample_count]\n",
        "validation_targets = shuffled_targets[train_sample_count:train_sample_count + validation_sample_count]\n",
        "\n",
        "test_inputs = shuffled_inputs[train_sample_count + validation_sample_count:]\n",
        "test_targets = shuffled_targets[train_sample_count + validation_sample_count:]\n",
        "\n",
        "print(np.sum(train_targets), train_sample_count, np.sum(train_targets) / train_sample_count)\n",
        "print(np.sum(validation_targets), validation_sample_count, np.sum(validation_targets) / validation_sample_count)\n",
        "print(np.sum(test_targets), test_sample_count, np.sum(test_targets) / test_sample_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXdykA7PQhHc",
        "outputId": "e51a3832-9c84-4443-c973-98d97e9b0eb6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1800.0 3579 0.5029337803855826\n",
            "209.0 447 0.46756152125279643\n",
            "228.0 448 0.5089285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "按常见比例划分：\n",
        "\n",
        "训练集 (Train)：80%（number of the element * 0.8）\n",
        "\n",
        "验证集 (Validation)：10%（number of the element * 0.1）\n",
        "\n",
        "测试集 (Test)：10% (number of the element - 训练集 - 验证集)"
      ],
      "metadata": {
        "id": "UghyCuxVdzuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**np.sum(train_targets)** 标签为 1 的样本数量\n",
        "\n",
        "**train_sample_count** 该集合的总样本数\n",
        "\n",
        "**np.sum(train_targets) / train_sample_count** 0和1 的比例"
      ],
      "metadata": {
        "id": "nwBlvgPVftk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('Audiobooks_data_train', inputs = train_inputs, targets = train_targets)\n",
        "np.savez('Audiobooks_data_validation', inputs = validation_inputs, targets = validation_targets)\n",
        "np.savez('Audiobooks_data_test', inputs = test_inputs, targets = test_targets)"
      ],
      "metadata": {
        "id": "auB812m6YLga"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the three datasets in .npz"
      ],
      "metadata": {
        "id": "ZyDVUN_NQqMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create the machine learning algorithm**"
      ],
      "metadata": {
        "id": "bOz4z_CzpSfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import the relevant libraries**"
      ],
      "metadata": {
        "id": "b2TKH6DdpSNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "FI6n0kIZ22KC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data**"
      ],
      "metadata": {
        "id": "2DPwmHPL27u3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "npz_train = np.load('Audiobooks_data_train.npz')\n",
        "\n",
        "train_inputs = npz_train['inputs'].astype(np.float64)\n",
        "train_targets = npz_train['targets'].astype(np.int64)\n",
        "\n",
        "npz_validation = np.load('Audiobooks_data_validation.npz')\n",
        "validation_inputs, validation_targets = npz_validation['inputs'].astype(np.float64), npz_validation['targets'].astype(np.int64)\n",
        "\n",
        "npz_test = np.load('Audiobooks_data_test.npz')\n",
        "test_inputs, test_targets = npz_test['inputs'].astype(np.float64), npz_test['targets'].astype(np.int64)"
      ],
      "metadata": {
        "id": "yFeG0eEw274q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "重新加载训练集文件，并把类型转换：\n",
        "\n",
        "**float64 用于输入特征（神经网络输入必须是浮点数）**\n",
        "\n",
        "**int64 用于标签（分类任务的类别编号）**"
      ],
      "metadata": {
        "id": "r82Uq65pijpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "vvzjPdfr365u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**outline, optimizers, loss, stopping and training**"
      ],
      "metadata": {
        "id": "gYN0UB9c38P-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 10\n",
        "output_size = 2\n",
        "hidden_layer_size = 50\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(output_size, activation = 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "duV-GAz24ESG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "输入层有 10 个特征(data feature)\n",
        "\n",
        "输出层有 2 个类别（会买 / 不会买）\n",
        "\n",
        "隐藏层设为 50 个神经元"
      ],
      "metadata": {
        "id": "javxzA5OjIkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fU3JUPxo4xsx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**optimizer='adam'**\n",
        "→ 自适应学习率优化器（训练速度快，效果稳定）\n",
        "\n",
        "**loss='sparse_categorical_crossentropy'**\n",
        "→ 适合目标是整数标签（0 和 1）的分类任务(classification)。\n",
        "\n",
        "**metrics=['accuracy']**\n",
        "→ 训练时输出准确率。"
      ],
      "metadata": {
        "id": "sSNFv3hHjRjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "max_epochs = 100\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
        "\n",
        "model.fit(train_inputs,\n",
        "          train_targets,\n",
        "          batch_size = batch_size,\n",
        "          epochs = max_epochs,\n",
        "          callbacks = [early_stopping],\n",
        "          validation_data = (validation_inputs, validation_targets),\n",
        "          verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVW1PLS05UtB",
        "outputId": "39e4a903-6ec1-49a9-f08b-d9b2a85756f7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "36/36 - 2s - 47ms/step - accuracy: 0.6859 - loss: 0.5821 - val_accuracy: 0.7338 - val_loss: 0.5030\n",
            "Epoch 2/100\n",
            "36/36 - 0s - 5ms/step - accuracy: 0.7597 - loss: 0.4767 - val_accuracy: 0.7539 - val_loss: 0.4417\n",
            "Epoch 3/100\n",
            "36/36 - 0s - 5ms/step - accuracy: 0.7706 - loss: 0.4283 - val_accuracy: 0.7740 - val_loss: 0.4102\n",
            "Epoch 4/100\n",
            "36/36 - 0s - 5ms/step - accuracy: 0.7829 - loss: 0.4002 - val_accuracy: 0.7696 - val_loss: 0.3846\n",
            "Epoch 5/100\n",
            "36/36 - 0s - 4ms/step - accuracy: 0.7958 - loss: 0.3824 - val_accuracy: 0.7718 - val_loss: 0.3733\n",
            "Epoch 6/100\n",
            "36/36 - 0s - 5ms/step - accuracy: 0.7930 - loss: 0.3704 - val_accuracy: 0.7875 - val_loss: 0.3697\n",
            "Epoch 7/100\n",
            "36/36 - 0s - 5ms/step - accuracy: 0.8033 - loss: 0.3638 - val_accuracy: 0.7830 - val_loss: 0.3617\n",
            "Epoch 8/100\n",
            "36/36 - 0s - 6ms/step - accuracy: 0.8075 - loss: 0.3568 - val_accuracy: 0.7897 - val_loss: 0.3566\n",
            "Epoch 9/100\n",
            "36/36 - 0s - 8ms/step - accuracy: 0.8064 - loss: 0.3519 - val_accuracy: 0.7897 - val_loss: 0.3538\n",
            "Epoch 10/100\n",
            "36/36 - 0s - 7ms/step - accuracy: 0.8108 - loss: 0.3468 - val_accuracy: 0.7987 - val_loss: 0.3420\n",
            "Epoch 11/100\n",
            "36/36 - 0s - 7ms/step - accuracy: 0.8078 - loss: 0.3444 - val_accuracy: 0.7852 - val_loss: 0.3448\n",
            "Epoch 12/100\n",
            "36/36 - 0s - 8ms/step - accuracy: 0.8189 - loss: 0.3374 - val_accuracy: 0.7875 - val_loss: 0.3419\n",
            "Epoch 13/100\n",
            "36/36 - 0s - 8ms/step - accuracy: 0.8159 - loss: 0.3365 - val_accuracy: 0.7852 - val_loss: 0.3415\n",
            "Epoch 14/100\n",
            "36/36 - 0s - 7ms/step - accuracy: 0.8184 - loss: 0.3361 - val_accuracy: 0.7830 - val_loss: 0.3402\n",
            "Epoch 15/100\n",
            "36/36 - 0s - 7ms/step - accuracy: 0.8203 - loss: 0.3335 - val_accuracy: 0.7897 - val_loss: 0.3371\n",
            "Epoch 16/100\n",
            "36/36 - 0s - 9ms/step - accuracy: 0.8243 - loss: 0.3302 - val_accuracy: 0.8031 - val_loss: 0.3325\n",
            "Epoch 17/100\n",
            "36/36 - 0s - 8ms/step - accuracy: 0.8248 - loss: 0.3293 - val_accuracy: 0.7942 - val_loss: 0.3359\n",
            "Epoch 18/100\n",
            "36/36 - 0s - 6ms/step - accuracy: 0.8198 - loss: 0.3300 - val_accuracy: 0.8031 - val_loss: 0.3360\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7894566e3f50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**batch_size = 100** 每个批次 100 条样本\n",
        "**max_epochs = 100** 最多训练 100 轮\n",
        "\n",
        "**model.fit()** 训练数据\n",
        "\n",
        "**early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)**\n",
        "\n",
        "如果验证集连续 2 轮不再提升，就提前停止（避免过拟合）。\n",
        "\n",
        "**verbose=2** 每个 epoch 打印一行日志。\n"
      ],
      "metadata": {
        "id": "vwirsQb8kH3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**callbacks（回调函数）**  是一种机制，\n",
        "可以在模型训练的不同阶段（比如每个 epoch 结束时）执行一些额外操作，比如：\n",
        "\n",
        "保存模型（ModelCheckpoint）\n",
        "\n",
        "动态调整学习率（ReduceLROnPlateau）\n",
        "\n",
        "提前停止训练（EarlyStopping）\n",
        "\n",
        "**patience=2** 连续 2 次没提升后才停止"
      ],
      "metadata": {
        "id": "srt8-fHDDQDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch_size（批大小）\n",
        "\n",
        "每次训练更新权重时用多少样本。\n",
        "\n",
        "| 常见取值                 | 特点                  |\n",
        "| -------------------- | ------------------- |\n",
        "| **16 / 32**          | 小批次，噪声大但泛化好（适合小数据集） |\n",
        "| **64 / 128**         | 常见默认值，兼顾速度与稳定性      |\n",
        "| **256 / 512 / 1024** | 大批次，收敛快但可能过拟合（需大显存） |\n"
      ],
      "metadata": {
        "id": "opbkGUplD4AX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "max_epochs（最大轮数）\n",
        "\n",
        "指整个数据集会被训练多少次。\n",
        "\n",
        "| 常见取值       | 适用场景                            |\n",
        "| ---------- | ------------------------------- |\n",
        "| **10–20**  | 简单模型（如逻辑回归、浅层网络）                |\n",
        "| **50–100** | 一般深度学习模型（CNN, RNN）              |\n",
        "| **>200**   | 复杂模型（ResNet、Transformer等）或小学习率时 |\n"
      ],
      "metadata": {
        "id": "TihutcULD9om"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test the model**"
      ],
      "metadata": {
        "id": "jEjl1Suu8BVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IzxAQIa8EZW",
        "outputId": "dfeb8bd2-a0bb-4c79-be32-823b722f72f0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8605 - loss: 0.3281 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model.evaluate()** 测试数据"
      ],
      "metadata": {
        "id": "CWfHyc__p_85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHoxmUas8Emt",
        "outputId": "a13db729-af2f-4130-d269-fff9aeeb7750"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test loss: 0.33. Test accuracy: 83.71%\n"
          ]
        }
      ]
    }
  ]
}